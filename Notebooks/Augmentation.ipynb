{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["! pip install deep-utils\n","! pip install datasets\n","\n","! pip install transformers[torch]\n","! pip install accelerate -U\n","%pip install audiomentations"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.io import wavfile\n","import librosa\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n","from deep_utils import warmup_cosine\n","\n","from datasets import load_dataset, Audio, Dataset\n","from transformers import AutoFeatureExtractor\n","from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train = pd.read_csv(\"/kaggle/input/biomed-datathon-bmefest2/train.csv\")\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["patient_id_to_drop = \"patient_085\"\n","train = train[train[\"patient_id\"] != patient_id_to_drop]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["label_encoder = LabelEncoder()\n","train[\"labels\"] = label_encoder.fit_transform(\n","    np.argmax(train[[\"AS\", \"AR\", \"MR\", \"MS\", \"N\"]], axis=1)\n",")\n","train.drop(\n","    [\n","        \"AS\",\n","        \"AR\",\n","        \"MR\",\n","        \"MS\",\n","        \"N\",\n","        \"recording_1\",\n","        \"recording_2\",\n","        \"recording_3\",\n","        \"recording_4\",\n","        \"recording_5\",\n","        \"recording_6\",\n","        \"recording_7\",\n","        \"recording_8\",\n","    ],\n","    axis=1,\n","    inplace=True,\n",")\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["BASE_URL = \"/kaggle/input/bio-med-merged/\"\n","train[\"path\"] = train[\"patient_id\"].apply(lambda x: BASE_URL + x + \".wav\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train.labels.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n","\n","augment = Compose(\n","    [\n","        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=1),\n","        TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n","        PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n","        Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def load_audio(file_path):\n","    audio, sr = librosa.load(file_path, sr=None)\n","    return audio, sr\n","\n","\n","def save_audio(audio, file_path, sr):\n","    wavfile.write(file_path, sr, (audio * 32767).astype(np.int16))\n","\n","\n","def augment_and_update_df(df, augmenter, pre_name=\"aug_\"):\n","    augmented_data = []\n","    for index, row in df.iterrows():\n","        audio_file = row[\"path\"]\n","        new_name = pre_name + audio_file.split(\"/\")[-1]\n","        label = row[\"labels\"]\n","        audio, sample_rate = load_audio(audio_file)\n","        augmented_audio = augmenter(samples=audio, sample_rate=sample_rate)\n","        new_file_name = f\"/kaggle/working/{new_name}\"\n","        augmented_data.append((new_name, new_file_name, label))\n","        save_audio(augmented_audio, new_file_name, sample_rate)\n","\n","    augmented_df = pd.DataFrame(\n","        augmented_data, columns=[\"patient_id\", \"path\", \"labels\"]\n","    )\n","    df = pd.concat([df, augmented_df], ignore_index=True)\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train = augment_and_update_df(train, augment)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train[\"audio\"] = train[\"path\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["strat_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=31)\n","for train_index, val_index in strat_split.split(train, train[\"labels\"]):\n","    train_df = train.iloc[train_index]\n","    val_df = train.iloc[val_index]\n","\n","unique_classes_in_test_set = val_df.labels.value_counts()\n","print(\"Classes present in the test set:\", unique_classes_in_test_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_ds = Dataset.from_pandas(train_df)\n","val_ds = Dataset.from_pandas(val_df)\n","\n","train_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_ds = train_ds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n","val_ds = val_ds.cast_column(\"audio\", Audio(sampling_rate=16_000))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(train_ds), len(val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["labels = [\"AS\", \"AR\", \"MR\", \"MS\", \"N\"]\n","\n","label2id, id2label = dict(), dict()\n","for i, label in enumerate(labels):\n","    label2id[label] = str(i)\n","    id2label[str(i)] = label\n","label2id"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoFeatureExtractor, ASTForAudioClassification"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["feature_extractor = AutoFeatureExtractor.from_pretrained(\n","    \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def preprocess_function(examples):\n","    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n","    inputs = feature_extractor(\n","        audio_arrays,\n","        sampling_rate=feature_extractor.sampling_rate,\n","        max_length=16000,\n","        truncation=True,\n","    )\n","    return inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["np.object = object "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["encoded_train = train_ds.map(preprocess_function, remove_columns=\"audio\", batched=True)\n","encoded_val = val_ds.map(preprocess_function, remove_columns=\"audio\", batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import (\n","    accuracy_score,\n","    f1_score,\n","    recall_score,\n","    precision_score,\n","    confusion_matrix,\n",")\n","\n","\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=1)\n","    acc = accuracy_score(labels, predictions)\n","    f1 = f1_score(labels, predictions, average=\"weighted\")\n","    recall = recall_score(labels, predictions, average=\"weighted\")\n","    precision = precision_score(labels, predictions, average=\"weighted\")\n","    macro_f1 = f1_score(labels, predictions, average=\"macro\")\n","\n","    cm = confusion_matrix(labels, predictions)\n","    tn = cm[0, 0]\n","    fp = cm[0, 1]\n","    fn = cm[1, 0]\n","    tp = cm[1, 1]\n","    sensitivity = tp / (tp + fn)\n","    specificity = tn / (tn + fp)\n","\n","    icbhi_score = (sensitivity + specificity) / 2\n","\n","    return {\n","        \"accuracy\": acc,\n","        \"f1\": f1,\n","        \"macro-f1\": macro_f1,\n","        \"recall\": recall,\n","        \"precision\": precision,\n","        \"sensitivity\": sensitivity,\n","        \"specificity\": specificity,\n","        \"icbhi\": icbhi_score,\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AdamW, get_linear_schedule_with_warmup"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import math\n","from transformers import EarlyStoppingCallback\n","\n","early_stopping = EarlyStoppingCallback(early_stopping_patience=5)\n","\n","train_bs = 4\n","epochs = 25\n","lr = 1e-6\n","lrf = lr\n","output_dir = \"./results\"\n","total_steps = int((np.ceil(encoded_train.num_rows / train_bs) * epochs))\n","\n","num_labels = len(id2label)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = ASTForAudioClassification.from_pretrained(\n","    \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=output_dir,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    num_train_epochs=epochs,\n","    gradient_accumulation_steps=4,\n","    fp16=True,\n","    load_best_model_at_end=True,\n","    save_total_limit=1,\n","    metric_for_best_model=\"loss\",\n","    per_device_train_batch_size=train_bs,\n","    per_device_eval_batch_size=8,\n","    logging_steps=1,\n","    report_to=\"none\",\n","    greater_is_better=False,\n",")\n","\n","weight_decay = 0.01\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=encoded_train,\n","    eval_dataset=encoded_val,\n","    tokenizer=feature_extractor,\n","    compute_metrics=compute_metrics,\n","    optimizers=(optimizer, scheduler),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["eval_results = trainer.evaluate()\n","\n","print(\"Evaluation results:\", eval_results)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test = pd.read_csv(\"/kaggle/input/biomed-datathon-bmefest2/test_files.csv\")\n","test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["BASE_URL = \"/kaggle/input/biomed-datathon-bmefest2/test/\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test[\"recording_1\"] = test[\"recording_1\"].apply(lambda x: BASE_URL + x + \".wav\")\n","test[\"recording_2\"] = test[\"recording_2\"].apply(lambda x: BASE_URL + x + \".wav\")\n","test[\"recording_3\"] = test[\"recording_3\"].apply(lambda x: BASE_URL + x + \".wav\")\n","test[\"recording_4\"] = test[\"recording_4\"].apply(lambda x: BASE_URL + x + \".wav\")\n","test[\"recording_5\"] = test[\"recording_5\"].apply(lambda x: BASE_URL + x + \".wav\")\n","test[\"recording_6\"] = test[\"recording_6\"].apply(lambda x: BASE_URL + x + \".wav\")\n","test[\"recording_7\"] = test[\"recording_7\"].apply(lambda x: BASE_URL + x + \".wav\")\n","test[\"recording_8\"] = test[\"recording_8\"].apply(lambda x: BASE_URL + x + \".wav\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from pydub import AudioSegment\n","\n","\n","def merge_audio(files):\n","    merged = AudioSegment.empty()\n","\n","    for file in files:\n","        audio = AudioSegment.from_file(file)\n","        merged += audio\n","\n","    return merged\n","\n","\n","def save_merged_audio(merged, output_file):\n","    merged.export(output_file, format=\"wav\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","\n","output_dir = \"test_files\"\n","os.makedirs(output_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i in range(len(test)):\n","    files_to_merge = list(test.iloc[i][6:])\n","    merged_audio = merge_audio(files_to_merge)\n","    save_merged_audio(\n","        merged_audio,\n","        f\"{'test_files/patient_' + list(test.iloc[i][6:])[0].split('/')[-1][:3]}.wav\",\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["BASE_URL = \"/kaggle/working/test_files/\"\n","test[\"path\"] = test[\"patient_id\"].apply(lambda x: BASE_URL + x + \".wav\")\n","test[\"audio\"] = test[\"patient_id\"].apply(lambda x: BASE_URL + x + \".wav\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test.drop(\n","    [\n","        \"recording_1\",\n","        \"recording_2\",\n","        \"recording_3\",\n","        \"recording_4\",\n","        \"recording_5\",\n","        \"recording_6\",\n","        \"recording_7\",\n","        \"recording_8\",\n","    ],\n","    axis=1,\n","    inplace=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_ds = Dataset.from_pandas(test)\n","test_ds = test_ds.cast_column(\"audio\", Audio(sampling_rate=16_000))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["encoded_test = test_ds.map(preprocess_function, remove_columns=\"audio\", batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_preds = trainer.predict(encoded_test)\n","logits = test_preds.predictions\n","class_predictions_logits = np.argmax(logits, axis=-1)\n","\n","print(\"Class predictions from logits:\", class_predictions_logits)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["predicted_original_labels = label_encoder.inverse_transform(class_predictions_logits)\n","predicted_int_labels = predicted_original_labels.astype(int)\n","predicted_one_hot = np.eye(5)[predicted_original_labels]\n","\n","print(\"One-hot encoded predictions:\")\n","print(predicted_one_hot)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission_df = pd.DataFrame(predicted_one_hot, columns=[\"AS\", \"AR\", \"MR\", \"MS\", \"N\"])\n","\n","submission_df[\"patient_id\"] = test.patient_id\n","submission_df = submission_df[[\"patient_id\", \"AS\", \"AR\", \"MR\", \"MS\", \"N\"]]\n","\n","\n","submission_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission_df.to_csv('submission-aug2.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7683890,"sourceId":70055,"sourceType":"competition"},{"datasetId":4433830,"sourceId":7613753,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
